# -*- coding: utf-8 -*-
"""Gradient_Descent_Regressor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wdtCcqJuAzNHz8U_T-j3qVe7mesj6ely
"""

from sklearn.datasets import make_regression
import matplotlib.pyplot as plt
import numpy as np

X, Y = make_regression(n_samples=100, n_features=1, n_informative=1, n_targets=1, noise=20)

plt.scatter(X, Y)

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X, Y)

m = model.coef_[0]
print(f"Slope is: {m}")

b = model.intercept_
print(f"Intercept is: {b}")

class GDRegressor:

  def __init__(self, learning_rate, epochs):
    self.m = 6.727192897015373
    self.b = -120
    self.lr = learning_rate
    self.epochs = epochs

  def fit(self, X, Y):

    # Calculate the b using GD
    for i in range(self.epochs):
      loss_slope = -2 * np.sum(Y - self.m * X.ravel() - self.b)
      self.b = self.b - (self.lr * loss_slope)
    print(self.b)

gd = GDRegressor(0.001, 100)

gd.fit(X, Y)