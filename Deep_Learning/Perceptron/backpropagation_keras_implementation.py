# -*- coding: utf-8 -*-
"""Backpropagation_Keras_implementation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bHAJ-q8Uy7hKX6EPXg_ReKYFXuIpm_KW
"""

import numpy as np
import pandas as pd

data = pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]],columns=['cgpa','profile_score','lpa'])

print(data)

import tensorflow
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense

model = Sequential()

# Hidden layer
model.add(Dense(2,activation='linear',input_dim=2))
# Output layer
model.add(Dense(1,activation='linear'))

model.summary()

model.get_weights()

new_weights = [np.array([[0.1,0.1],[0.1,0.1]], dtype=np.float32),
               np.array([0.,0.], dtype=np.float32),
               np.array([[0.1],[0.1]], dtype=np.float32),
               np.array([0.], dtype=np.float32)]

model.set_weights(new_weights)

model.get_weights()

optimizer = keras.optimizers.Adam(learning_rate=0.001)
model.compile(loss='mean_squared_error',optimizer=optimizer)

model.fit(data.iloc[:,0:-1].values, data['lpa'].values, epochs=75, verbose=1, batch_size=1)

model.get_weights()